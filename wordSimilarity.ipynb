{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8193f83a-3d2a-4f62-b871-5f12e62ec500",
   "metadata": {},
   "source": [
    "# Word Vectors and similarity\n",
    "Word Vectors are numerical vector representations of words and documents. The numeric form helps understand the semantics about the word and can be used for NLP tasks such as classification.\n",
    "\n",
    "Because, vector representation of words that are similar in meaning and context appear closer together.\n",
    "\n",
    "spaCy models support inbuilt vectors that can be accessed through directly through the attributes of Token and Doc.\n",
    "\n",
    "First, load a spaCy model of your choice. Here, I am using the medium model for english en_core_web_md. Next, tokenize your text document with nlp boject of spacy model.\n",
    "\n",
    "You can check if a token has in-buit vector through Token.has_vector attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94547404-b278-48a1-8f5c-e15e9c5a0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.4 MB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-md==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.11)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (21.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (58.0.4)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.7.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7608d556-e75c-4955-a707-10adeeaa2f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I   True\n",
      "am   True\n",
      "an   True\n",
      "excellent   True\n",
      "cook   True\n"
     ]
    }
   ],
   "source": [
    "# Check if word vector is available\n",
    "import spacy\n",
    "\n",
    "# Loading a spacy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "tokens = nlp(\"I am an excellent cook\")\n",
    "\n",
    "for token in tokens:\n",
    "  print(token.text ,' ',token.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23eb0e81-68b4-40bd-a227-eccf4c975e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I   True\n",
      "wish   True\n",
      "to   True\n",
      "go   True\n",
      "to   True\n",
      "hogwarts   True\n",
      "lolXD   False\n"
     ]
    }
   ],
   "source": [
    "# Check if word vector is available\n",
    "tokens=nlp(\"I wish to go to hogwarts lolXD \")\n",
    "for token in tokens:\n",
    "  print(token.text,' ',token.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7cae1d0-6f79-4c96-b266-2d67fb4ccef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I   6.4231944\n",
      "wish   5.1652417\n",
      "to   4.74484\n",
      "go   5.05723\n",
      "to   4.74484\n",
      "hogwarts   7.4110312\n",
      "lolXD   0.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the word Vector\n",
    "tokens=nlp(\"I wish to go to hogwarts lolXD \")\n",
    "for token in tokens:\n",
    "  print(token.text,' ',token.vector_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dfdf41-3819-4812-9fef-539912f01c88",
   "metadata": {},
   "source": [
    "Notice that when vector is not present for a token, the value of vector_norm is 0 for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7429dad8-bdd9-435c-8bf9-d13cd2253719",
   "metadata": {},
   "source": [
    "Identifying similarity of two words or tokens is very crucial . It is the base to many everyday NLP tasks like text classification , recommendation systems, etc.. It is necessary to know how similar two sentences are , so they can be grouped in same or opposite category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ddded0-6e3f-4ce5-90a7-cb0ab5fd4869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773919122839211\n"
     ]
    }
   ],
   "source": [
    "# Compute Similarity\n",
    "token_1=nlp(\"bad\")\n",
    "token_2=nlp(\"terrible\")\n",
    "\n",
    "similarity_score=token_1.similarity(token_2)\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f30cdc-4bb7-49af-82a4-b4ffbe433c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between review 1 and 2 0.9566213306804962\n",
      "Similarity between review 3 and 4 0.8461898618188776\n"
     ]
    }
   ],
   "source": [
    "review_1=nlp(' The food was amazing')\n",
    "review_2=nlp('The food was excellent')\n",
    "review_3=nlp('I did not like the food')\n",
    "review_4=nlp('It was very bad experience')\n",
    "\n",
    "score_1=review_1.similarity(review_2)\n",
    "print('Similarity between review 1 and 2',score_1)\n",
    "\n",
    "score_2=review_3.similarity(review_4)\n",
    "print('Similarity between review 3 and 4',score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a897ce5-d668-46cc-be48-acbaacaf8f14",
   "metadata": {},
   "source": [
    "You can also check if two tokens or docs are related (includes both similar side and opposite sides) or completely irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561f24c6-b300-46f8-9a97-eb79ec6090ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza and burger   0.7269758060509472\n",
      "Pizza and chair   0.1917965994241628\n"
     ]
    }
   ],
   "source": [
    "# Compute Similarity between texts \n",
    "pizza=nlp('pizza')\n",
    "burger=nlp('burger')\n",
    "chair=nlp('chair')\n",
    "\n",
    "print('Pizza and burger  ',pizza.similarity(burger))\n",
    "print('Pizza and chair  ',pizza.similarity(chair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3f9ad-89b4-4696-bc99-2715b1f603c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
